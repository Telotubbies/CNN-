{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46086cf3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46086cf3",
    "outputId": "1cfbea55-4090-4f38-fc28-8e2536fbd5bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/ake/envs/rocm_env/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: pandas in /home/ake/envs/rocm_env/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: pillow in /home/ake/envs/rocm_env/lib/python3.12/site-packages (11.3.0)\n",
      "Requirement already satisfied: torch in /home/ake/envs/rocm_env/lib/python3.12/site-packages (2.10.0.dev20250925+rocm6.4)\n",
      "Requirement already satisfied: torchvision in /home/ake/envs/rocm_env/lib/python3.12/site-packages (0.25.0.dev20250926+rocm6.4)\n",
      "Requirement already satisfied: scikit-learn in /home/ake/envs/rocm_env/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: matplotlib in /home/ake/envs/rocm_env/lib/python3.12/site-packages (3.10.6)\n",
      "Requirement already satisfied: torchsummary in /home/ake/envs/rocm_env/lib/python3.12/site-packages (1.5.1)\n",
      "Requirement already satisfied: torchaudio in /home/ake/envs/rocm_env/lib/python3.12/site-packages (2.8.0.dev20250926+rocm6.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: filelock in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: pytorch-triton-rocm==3.5.0+gitbbb06c03 in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from torch) (3.5.0+gitbbb06c03)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from matplotlib) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ake/envs/rocm_env/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas pillow torch torchvision scikit-learn matplotlib torchsummary torchaudio \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b6785a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22b6785a",
    "outputId": "f1f1c73d-5de7-45c8-9136-3ffbf0cbebd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 3D-Print Defect Detection from CSV — ResNet-9 (scratch)\n",
    "# Train on images/all_images256, Test on images/test_images_oblique256 + test_images_silver265 (oblique=กล้องรอง,silver=กล้องรอง )\n",
    "# CSVs: general_data/all_images_no_filter.csv (train), general_data/all_images_no_filter.csv or specific test CSVs if needed\n",
    "# Works on ROCm/NVIDIA automatically. (AKE=7800xt,i5 13500H)\n",
    "\n",
    "import os, random, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.ops.misc import Conv2dNormActivation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import GroupShuffleSplit, StratifiedShuffleSplit\n",
    "\n",
    "# ========= Repro & Device =========\n",
    "SEED = 1337\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5da1043c-5521-4fa5-a4ee-2702c02b5e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0.dev20250925+rocm6.4\n",
      "6.4.43484-123eb5128\n",
      "True\n",
      "AMD Radeon RX 7800 XT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.hip)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c429c7ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c429c7ae",
    "outputId": "28cbec4c-80df-4ca9-fc79-62237a02588b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images (train domain & exists): 16287\n",
      "Split sizes -> Train: 11456  Test: 4831\n",
      "\n",
      "Train class counts:\n",
      " class\n",
      "0    5133\n",
      "1    3184\n",
      "2    2977\n",
      "4     162\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test class counts:\n",
      " class\n",
      "0    1893\n",
      "1    2328\n",
      "2     532\n",
      "4      78\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- พารามิเตอร์ที่ต้องตั้งให้ตรงโปรเจกต์ ---\n",
    "ROOT         = Path(\"/home/ake/envs/rocm_env/bin/CNN/Printing_Errors\")\n",
    "IMAGES_ROOT  = ROOT / \"images\"              # โฟลเดอร์ภาพหลัก\n",
    "TRAIN_SUBDIR = \"all_images256\"              # โฟลเดอร์ย่อยที่เก็บภาพ train\n",
    "CSV_MASTER   = ROOT / \"general_data\" / \"all_images_no_filter.csv\"  # CSV หลัก\n",
    "SPLIT_DIR    = ROOT / \"splits\"              # โฟลเดอร์สำหรับบันทึกผล split\n",
    "CLASS_RAW    = [0,1,2,4]                    # คลาสที่ต้องการใช้\n",
    "\n",
    "SPLIT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- โหลด CSV (ทน delimiter) ---\n",
    "df_master = pd.read_csv(CSV_MASTER, sep=None, engine='python', encoding='utf-8')\n",
    "df_master.columns = [c.strip() for c in df_master.columns]\n",
    "assert {\"image\",\"class\"}.issubset(df_master.columns), \"CSV must include 'image' and 'class'\"\n",
    "\n",
    "# --- คัดเฉพาะคลาสเป้าหมาย ---\n",
    "df_master = df_master[df_master[\"class\"].isin(CLASS_RAW)].copy()\n",
    "\n",
    "# --- ทำให้ path เป็น string/normalize ---\n",
    "df_master[\"image\"] = (\n",
    "    df_master[\"image\"].astype(str).str.strip().str.replace(\"\\\\\", \"/\", regex=False)\n",
    ")\n",
    "\n",
    "# --- เติมโฟลเดอร์ย่อย ถ้าไม่มี prefix โฟลเดอร์ ---\n",
    "def ensure_subdir_path(s: str) -> str:\n",
    "    return s if \"/\" in s else f\"{TRAIN_SUBDIR}/{s}\"\n",
    "df_master[\"image\"] = df_master[\"image\"].apply(ensure_subdir_path)\n",
    "\n",
    "# --- เก็บเฉพาะภาพที่อยู่ในโดเมน train_subdir ---\n",
    "df_master = df_master[df_master[\"image\"].str.startswith(f\"{TRAIN_SUBDIR}/\", na=False)].reset_index(drop=True)\n",
    "\n",
    "# --- เก็บเฉพาะไฟล์ที่มีอยู่จริง ---\n",
    "def exists_image(rel_path: str) -> bool:\n",
    "    return (Path(IMAGES_ROOT) / rel_path).exists()\n",
    "df_master = df_master[df_master[\"image\"].apply(exists_image)].reset_index(drop=True)\n",
    "\n",
    "print(\"Total images (train domain & exists):\", len(df_master))\n",
    "\n",
    "# --- แบ่ง Train/Test เท่านั้น: train ~70% / test ~30% ---\n",
    "def split_train_test(df, group_col=\"recording\", test_size=0.30, seed=42):\n",
    "    \"\"\"แบ่ง Train/Test เท่านั้น (ไม่มี validation)\"\"\"\n",
    "    if group_col in df.columns and df[group_col].notna().any():\n",
    "        groups = df[group_col].fillna(\"nogroup\")\n",
    "        gss = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
    "        i_tr, i_te = next(gss.split(df, groups=groups))\n",
    "        return df.iloc[i_tr].copy(), df.iloc[i_te].copy()\n",
    "    else:\n",
    "        y = df[\"class\"]\n",
    "        sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
    "        i_tr, i_te = next(sss.split(df, y))\n",
    "        return df.iloc[i_tr].copy(), df.iloc[i_te].copy()\n",
    "\n",
    "# --- ทำการ split และเซฟไฟล์ ---\n",
    "df_tr, df_te = split_train_test(df_master, group_col=\"recording\", test_size=0.30, seed=42)\n",
    "\n",
    "df_tr.to_csv(SPLIT_DIR/\"train.csv\", index=False)\n",
    "df_te.to_csv(SPLIT_DIR/\"test.csv\",  index=False)\n",
    "\n",
    "print(\"Split sizes -> Train:\", len(df_tr), \" Test:\", len(df_te))\n",
    "print(\"\\nTrain class counts:\\n\", df_tr[\"class\"].value_counts().sort_index())\n",
    "print(\"\\nTest class counts:\\n\",  df_te[\"class\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e0836aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 868
    },
    "id": "6e0836aa",
    "outputId": "9ec81271-51b6-4d73-da0f-ba13065b5f47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes | Train: (11456, 17) | Test: (4831, 17) | Val: None\n",
      "Class counts (train): {0: 5133, 1: 3184, 2: 2977, 4: 162}\n",
      "Class counts (test) : {0: 1893, 1: 2328, 2: 532, 4: 78}\n",
      "Exists rate -> Train: 11456/11456 (100.00%), Test: 4831/4831 (100.00%)\n",
      "\n",
      "[Train head]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "      <th>layer</th>\n",
       "      <th>nozzle</th>\n",
       "      <th>filament</th>\n",
       "      <th>ex_mul</th>\n",
       "      <th>retraction</th>\n",
       "      <th>layer_height</th>\n",
       "      <th>filament_color</th>\n",
       "      <th>shape</th>\n",
       "      <th>recording</th>\n",
       "      <th>printbed_color</th>\n",
       "      <th>extrusion_multiplier</th>\n",
       "      <th>extrusion_std</th>\n",
       "      <th>modified_layers</th>\n",
       "      <th>brightness</th>\n",
       "      <th>mean_brightness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all_images256/ELP_12MP_01.12.2022_166990882982...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>PLA</td>\n",
       "      <td>1.05</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>gray</td>\n",
       "      <td>1</td>\n",
       "      <td>Recording_01122022_15_27_47</td>\n",
       "      <td>black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all_images256/ELP_12MP_01.12.2022_166990882986...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>PLA</td>\n",
       "      <td>1.05</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>gray</td>\n",
       "      <td>1</td>\n",
       "      <td>Recording_01122022_15_27_47</td>\n",
       "      <td>black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all_images256/ELP_12MP_01.12.2022_166990887746...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>PLA</td>\n",
       "      <td>1.05</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>gray</td>\n",
       "      <td>1</td>\n",
       "      <td>Recording_01122022_15_27_47</td>\n",
       "      <td>black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  class  layer  nozzle  \\\n",
       "0  all_images256/ELP_12MP_01.12.2022_166990882982...      0      4     0.4   \n",
       "1  all_images256/ELP_12MP_01.12.2022_166990882986...      0      4     0.4   \n",
       "2  all_images256/ELP_12MP_01.12.2022_166990887746...      0      5     0.4   \n",
       "\n",
       "  filament ex_mul  retraction  layer_height filament_color shape  \\\n",
       "0      PLA   1.05         8.0           0.3           gray     1   \n",
       "1      PLA   1.05         8.0           0.3           gray     1   \n",
       "2      PLA   1.05         8.0           0.3           gray     1   \n",
       "\n",
       "                     recording printbed_color  extrusion_multiplier  \\\n",
       "0  Recording_01122022_15_27_47          black                   NaN   \n",
       "1  Recording_01122022_15_27_47          black                   NaN   \n",
       "2  Recording_01122022_15_27_47          black                   NaN   \n",
       "\n",
       "   extrusion_std modified_layers  brightness  mean_brightness  \n",
       "0            NaN             NaN         164              145  \n",
       "1            NaN             NaN         157              145  \n",
       "2            NaN             NaN         150              145  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Test head]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "      <th>layer</th>\n",
       "      <th>nozzle</th>\n",
       "      <th>filament</th>\n",
       "      <th>ex_mul</th>\n",
       "      <th>retraction</th>\n",
       "      <th>layer_height</th>\n",
       "      <th>filament_color</th>\n",
       "      <th>shape</th>\n",
       "      <th>recording</th>\n",
       "      <th>printbed_color</th>\n",
       "      <th>extrusion_multiplier</th>\n",
       "      <th>extrusion_std</th>\n",
       "      <th>modified_layers</th>\n",
       "      <th>brightness</th>\n",
       "      <th>mean_brightness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all_images256/ELP_12MP_01.12.2022_166992843887...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>PLA</td>\n",
       "      <td>1.05</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>gray</td>\n",
       "      <td>3</td>\n",
       "      <td>Recording_01122022_17_44_58</td>\n",
       "      <td>black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all_images256/ELP_12MP_01.12.2022_166992843891...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>PLA</td>\n",
       "      <td>1.05</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>gray</td>\n",
       "      <td>3</td>\n",
       "      <td>Recording_01122022_17_44_58</td>\n",
       "      <td>black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all_images256/ELP_12MP_01.12.2022_166992846382...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>PLA</td>\n",
       "      <td>1.05</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>gray</td>\n",
       "      <td>3</td>\n",
       "      <td>Recording_01122022_17_44_58</td>\n",
       "      <td>black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  class  layer  nozzle  \\\n",
       "0  all_images256/ELP_12MP_01.12.2022_166992843887...      0      4     0.4   \n",
       "1  all_images256/ELP_12MP_01.12.2022_166992843891...      0      4     0.4   \n",
       "2  all_images256/ELP_12MP_01.12.2022_166992846382...      0      5     0.4   \n",
       "\n",
       "  filament  ex_mul  retraction  layer_height filament_color shape  \\\n",
       "0      PLA    1.05         8.0           0.3           gray     3   \n",
       "1      PLA    1.05         8.0           0.3           gray     3   \n",
       "2      PLA    1.05         8.0           0.3           gray     3   \n",
       "\n",
       "                     recording printbed_color  extrusion_multiplier  \\\n",
       "0  Recording_01122022_17_44_58          black                   NaN   \n",
       "1  Recording_01122022_17_44_58          black                   NaN   \n",
       "2  Recording_01122022_17_44_58          black                   NaN   \n",
       "\n",
       "   extrusion_std modified_layers  brightness  mean_brightness  \n",
       "0            NaN             NaN         153              137  \n",
       "1            NaN             NaN         147              137  \n",
       "2            NaN             NaN         152              137  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train samples]\n",
      " - all_images256/ELP_12MP_14.02.2023_167639778843.png | exists: True\n",
      " - all_images256/ELP_12MP_21.12.2022_167165785322.png | exists: True\n",
      " - all_images256/ELP_12MP_17.02.2023_167664745761.png | exists: True\n",
      "\n",
      "[Val samples] (skipped: no file)\n",
      "\n",
      "[Test samples]\n",
      " - all_images256/ELP_12MP_04.01.2023_167284876744.png | exists: True\n",
      " - all_images256/ELP_12MP_23.02.2023_167716438692.png | exists: True\n",
      " - all_images256/ELP_12MP_06.12.2022_167036023452.png | exists: True\n"
     ]
    }
   ],
   "source": [
    "# === Load splits (val เป็นออปชัน) ===\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "# โหลด train/test (บังคับมี)\n",
    "df_tr = pd.read_csv(SPLIT_DIR/\"train.csv\")\n",
    "df_te = pd.read_csv(SPLIT_DIR/\"test.csv\")\n",
    "\n",
    "# โหลด val ถ้ามี\n",
    "val_path = SPLIT_DIR/\"val.csv\"\n",
    "df_va = pd.read_csv(val_path) if val_path.exists() else None\n",
    "\n",
    "print(\"Shapes | Train:\", df_tr.shape, \"| Test:\", df_te.shape, \"| Val:\", (df_va.shape if df_va is not None else None))\n",
    "\n",
    "# --- ฟังก์ชันช่วย ---\n",
    "def count_classes(df: pd.DataFrame):\n",
    "    vc = df[\"class\"].value_counts().sort_index()\n",
    "    return vc.to_dict()\n",
    "\n",
    "def exists_rate(df: pd.DataFrame, root: Path):\n",
    "    paths = [(root / p) for p in df[\"image\"].astype(str)]\n",
    "    n = len(paths)\n",
    "    n_ok = sum(p.exists() for p in paths)\n",
    "    return n_ok, n, (n_ok / n if n else 0.0)\n",
    "\n",
    "def sample_paths(df: pd.DataFrame, k=3):\n",
    "    k = min(k, len(df))\n",
    "    if k == 0: return []\n",
    "    return df.sample(k, random_state=1337)[\"image\"].astype(str).tolist()\n",
    "\n",
    "# --- นับคลาส ---\n",
    "print(\"Class counts (train):\", count_classes(df_tr))\n",
    "if df_va is not None:\n",
    "    print(\"Class counts (val)  :\", count_classes(df_va))\n",
    "print(\"Class counts (test) :\", count_classes(df_te))\n",
    "\n",
    "# --- ตรวจไฟล์มีจริงในดิสก์ ---\n",
    "ok_tr, n_tr, r_tr = exists_rate(df_tr, IMAGES_ROOT)\n",
    "if df_va is not None:\n",
    "    ok_va, n_va, r_va = exists_rate(df_va, IMAGES_ROOT)\n",
    "ok_te, n_te, r_te = exists_rate(df_te, IMAGES_ROOT)\n",
    "\n",
    "msg_val = f\", Val: {ok_va}/{n_va} ({r_va:.2%})\" if df_va is not None else \"\"\n",
    "print(f\"Exists rate -> Train: {ok_tr}/{n_tr} ({r_tr:.2%}){msg_val}, Test: {ok_te}/{n_te} ({r_te:.2%})\")\n",
    "\n",
    "# --- โชว์ head ---\n",
    "print(\"\\n[Train head]\")\n",
    "display(df_tr.head(3))\n",
    "if df_va is not None:\n",
    "    print(\"\\n[Val head]\")\n",
    "    display(df_va.head(3))\n",
    "print(\"\\n[Test head]\")\n",
    "display(df_te.head(3))\n",
    "\n",
    "# --- ตัวอย่างพาธและสถานะไฟล์ ---\n",
    "for name, df in [(\"Train\", df_tr), (\"Val\", df_va), (\"Test\", df_te)]:\n",
    "    if df is None:\n",
    "        print(f\"\\n[{name} samples] (skipped: no file)\")\n",
    "        continue\n",
    "    print(f\"\\n[{name} samples]\")\n",
    "    for rel in sample_paths(df, k=3):\n",
    "        p = IMAGES_ROOT / rel\n",
    "        print(\" -\", rel, \"| exists:\", p.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "JTKNcbmaHxj8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JTKNcbmaHxj8",
    "outputId": "60889b27-5a66-48e7-e569-1043adaed94f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class counts:\n",
      " class\n",
      "Good               5133\n",
      "Under-Extrusion    3184\n",
      "Stringing          2977\n",
      "Spaghetti           162\n",
      "Name: count, dtype: int64\n",
      "Test class counts:\n",
      " class\n",
      "Under-Extrusion    2328\n",
      "Good               1893\n",
      "Stringing           532\n",
      "Spaghetti            78\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# mapping raw class id -> label name\n",
    "CLASS_NAMES = {\n",
    "    0: \"Good\",\n",
    "    1: \"Under-Extrusion\",\n",
    "    2: \"Stringing\",\n",
    "    4: \"Spaghetti\"\n",
    "}\n",
    "\n",
    "print(\"Train class counts:\\n\", df_tr[\"class\"].map(CLASS_NAMES).value_counts())\n",
    "print(\"Test class counts:\\n\",  df_te[\"class\"].map(CLASS_NAMES).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0820d3d",
   "metadata": {
    "id": "c0820d3d"
   },
   "outputs": [],
   "source": [
    "# --- Custom Dataset ---\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.root_dir / self.df.loc[idx, \"image\"]\n",
    "        label = int(self.df.loc[idx, \"class\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# --- Transform ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(...)  # ใส่ถ้าคุณมี mean/std\n",
    "])\n",
    "\n",
    "# --- Dataset ---\n",
    "ds_train = CustomImageDataset(df_tr, IMAGES_ROOT, transform=transform)\n",
    "ds_test  = CustomImageDataset(df_te, IMAGES_ROOT, transform=transform)\n",
    "\n",
    "# --- DataLoader ---\n",
    "BATCH = 8\n",
    "kwargs = dict(batch_size=BATCH, num_workers=0, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "train_ld = DataLoader(ds_train, shuffle=True,  **kwargs)\n",
    "test_ld  = DataLoader(ds_test,  shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1aa05d6",
   "metadata": {
    "id": "f1aa05d6"
   },
   "outputs": [],
   "source": [
    "num_classes = 4 \n",
    "# ========= Model: ResNet-9 =========\n",
    "def conv_bn_relu(in_c, out_c, k=3, s=1, p=1):\n",
    "    return Conv2dNormActivation(in_c, out_c, kernel_size=k, stride=s, padding=p,\n",
    "                                norm_layer=nn.BatchNorm2d, activation_layer=nn.ReLU)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv_bn_relu(c, c)\n",
    "        self.conv2 = Conv2dNormActivation(c, c, kernel_size=3, padding=1,\n",
    "                                          norm_layer=nn.BatchNorm2d, activation_layer=None)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        id = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x + id\n",
    "        return self.relu(x)\n",
    "\n",
    "class ResNet9(nn.Module):\n",
    "    def __init__(self, in_ch=3, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.layer1 = conv_bn_relu(in_ch, 64, 3, 1, 1)\n",
    "        self.layer2 = conv_bn_relu(64, 128, 3, 2, 1)  # /2\n",
    "        self.res1   = BasicBlock(128)\n",
    "        self.layer3 = conv_bn_relu(128, 256, 3, 2, 1) # /4\n",
    "        self.layer4 = conv_bn_relu(256, 512, 3, 2, 1) # /8\n",
    "        self.res2   = BasicBlock(512)\n",
    "        self.pool   = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc     = nn.Linear(512, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x); x = self.res1(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x); x = self.res2(x)\n",
    "        x = self.pool(x).flatten(1)\n",
    "        return self.fc(x)\n",
    "\n",
    "model = ResNet9(num_classes=num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd3886c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 128, 128]           1,728\n",
      "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
      "              ReLU-3         [-1, 64, 128, 128]               0\n",
      "            Conv2d-4          [-1, 128, 64, 64]          73,728\n",
      "       BatchNorm2d-5          [-1, 128, 64, 64]             256\n",
      "              ReLU-6          [-1, 128, 64, 64]               0\n",
      "            Conv2d-7          [-1, 128, 64, 64]         147,456\n",
      "       BatchNorm2d-8          [-1, 128, 64, 64]             256\n",
      "              ReLU-9          [-1, 128, 64, 64]               0\n",
      "           Conv2d-10          [-1, 128, 64, 64]         147,456\n",
      "      BatchNorm2d-11          [-1, 128, 64, 64]             256\n",
      "             ReLU-12          [-1, 128, 64, 64]               0\n",
      "       BasicBlock-13          [-1, 128, 64, 64]               0\n",
      "           Conv2d-14          [-1, 256, 32, 32]         294,912\n",
      "      BatchNorm2d-15          [-1, 256, 32, 32]             512\n",
      "             ReLU-16          [-1, 256, 32, 32]               0\n",
      "           Conv2d-17          [-1, 512, 16, 16]       1,179,648\n",
      "      BatchNorm2d-18          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-19          [-1, 512, 16, 16]               0\n",
      "           Conv2d-20          [-1, 512, 16, 16]       2,359,296\n",
      "      BatchNorm2d-21          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-22          [-1, 512, 16, 16]               0\n",
      "           Conv2d-23          [-1, 512, 16, 16]       2,359,296\n",
      "      BatchNorm2d-24          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-25          [-1, 512, 16, 16]               0\n",
      "       BasicBlock-26          [-1, 512, 16, 16]               0\n",
      "AdaptiveAvgPool2d-27            [-1, 512, 1, 1]               0\n",
      "           Linear-28                    [-1, 4]           2,052\n",
      "================================================================\n",
      "Total params: 6,570,052\n",
      "Trainable params: 6,570,052\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 80.00\n",
      "Params size (MB): 25.06\n",
      "Estimated Total Size (MB): 105.25\n",
      "----------------------------------------------------------------\n",
      "Output shape: torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "# ตรวจสอบ model summary\n",
    "from torchsummary import summary\n",
    "summary(model, (3, 128, 128))  # ถ้า input size 128x128 RGB\n",
    "\n",
    "# ตรวจสอบ output\n",
    "x = torch.randn(4, 3, 128, 128).to(device)\n",
    "y = model(x)\n",
    "print(\"Output shape:\", y.shape)  # [4, 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb655ca",
   "metadata": {
    "id": "eeb655ca"
   },
   "outputs": [],
   "source": [
    "# ========= Train (no valid set) =========\n",
    "EPOCHS = 30\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "use_amp = torch.cuda.is_available()\n",
    "scaler = torch.amp.GradScaler(\"cuda\", enabled=use_amp)\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    total, correct, run_loss = 0, 0, 0.0\n",
    "    for x, y in train_ld:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        #  ใช้ torch.amp.autocast\n",
    "        with torch.amp.autocast(\"cuda\", enabled=use_amp):\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        run_loss += loss.item() * x.size(0)\n",
    "        correct  += (logits.argmax(1) == y).sum().item()\n",
    "        total    += x.size(0)\n",
    "\n",
    "    print(f\"Epoch {ep:02d}/{EPOCHS}  loss {run_loss/total:.4f}  acc {correct/total:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec48a70",
   "metadata": {
    "id": "7ec48a70"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ========= Test score + Confusion Matrix =========\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.inference_mode(), torch.cuda.amp.autocast(enabled=use_amp):\n",
    "    for x, y in test_ld:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        y_true.extend(y.numpy().tolist())\n",
    "        y_pred.extend(logits.argmax(1).cpu().numpy().tolist())\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\n=== TEST SCORE ===\\nAccuracy: {acc:.4f}\")\n",
    "cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,5), dpi=150)\n",
    "ConfusionMatrixDisplay(cm, display_labels=[str(r) for r in idx2raw]).plot(ax=ax, cmap=\"Blues\", values_format=\"d\", colorbar=False)\n",
    "plt.title(\"Confusion Matrix (counts)\"); plt.tight_layout()\n",
    "plt.setp(ax.get_xticklabels(), rotation=90); plt.show()\n",
    "\n",
    "cm_norm = cm.astype(float) / cm.sum(axis=1, keepdims=True)\n",
    "fig, ax = plt.subplots(figsize=(6,5), dpi=150)\n",
    "ConfusionMatrixDisplay(cm_norm, display_labels=[str(r) for r in idx2raw]).plot(ax=ax, cmap=\"Blues\", values_format=\".2f\", colorbar=True)\n",
    "plt.title(\"Confusion Matrix (row-normalized)\"); plt.tight_layout()\n",
    "plt.setp(ax.get_xticklabels(), rotation=90); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046756a4-16f6-482a-a58d-3702efa771d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22f7121-a260-432f-8573-e28568433b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (ROCmV2)",
   "language": "python",
   "name": "rocm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
